{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ef35cc0-c2ca-4ff8-a4c5-043f1035482f",
   "metadata": {},
   "source": [
    "# 8-4. 텍스트 분류 실습 - 20 뉴스그룹 분류\n",
    "\n",
    "\t• what to do? 20 뉴스그룹 데이터 세트를 이용해 텍스트 분류를 적용하기\n",
    "\t• 텍스트 분류란? 특정 문서의 분류를 학습 데이터를 통해 학습해 모델을 생성한 뒤 학습 모델을 이용해 다른 문서의 분류를 예측\n",
    "    사이킷런의 fetch_20newsgroups() : 예제 데이터 제공\n",
    "\t• 텍스트 정규화 > 텍스트의 피처 벡터화 (희소 행렬 형태로 > 로지스틱 회귀로 분류 수행) > 머신러닝 알고리즘 적용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a14e09-4bd9-412c-995d-1a63355ff5a0",
   "metadata": {},
   "source": [
    "## 1. 텍스트 정규화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10764ea6-2e10-42f2-a768-7d7362ca5d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetch_20newsgroups()로 인터넷에서 로컬로 데이터 내려받기\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "#로컬 데이터 경로\n",
    "data_home=\"/Users/bluecloud/Documents/대학/유런/데이터셋/20news-bydate-test\"\n",
    "# 데이터셋 로드\n",
    "news_data = fetch_20newsgroups(data_home=data_home, subset='all', random_state=156)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "95f3c7c0-9741-496e-8134-34d776d5ba17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'filenames', 'target_names', 'target', 'DESCR'])\n"
     ]
    }
   ],
   "source": [
    "#키값 확인\n",
    "print(news_data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ea0f1f04-43b3-4cca-aa0b-859194b1db9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target 클래스의 값과 분포도 \n",
      " <bound method Series.sort_index of 10    999\n",
      "15    997\n",
      "8     996\n",
      "9     994\n",
      "11    991\n",
      "13    990\n",
      "7     990\n",
      "5     988\n",
      "14    987\n",
      "2     985\n",
      "12    984\n",
      "3     982\n",
      "6     975\n",
      "1     973\n",
      "4     963\n",
      "17    940\n",
      "16    910\n",
      "0     799\n",
      "18    775\n",
      "19    628\n",
      "Name: count, dtype: int64>\n",
      "target 클래스의 이름들 \n",
      " ['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n"
     ]
    }
   ],
   "source": [
    "#target 클래스 구성 확인\n",
    "import pandas as pd\n",
    "\n",
    "print('target 클래스의 값과 분포도 \\n',pd.Series(news_data.target).value_counts().sort_index)\n",
    "print('target 클래스의 이름들 \\n',news_data.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f2ed3d3f-6405-420d-bdef-0a8717488952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: egreen@east.sun.com (Ed Green - Pixel Cruncher)\n",
      "Subject: Re: Observation re: helmets\n",
      "Organization: Sun Microsystems, RTP, NC\n",
      "Lines: 21\n",
      "Distribution: world\n",
      "Reply-To: egreen@east.sun.com\n",
      "NNTP-Posting-Host: laser.east.sun.com\n",
      "\n",
      "In article 211353@mavenry.altcit.eskimo.com, maven@mavenry.altcit.eskimo.com (Norman Hamer) writes:\n",
      "> \n",
      "> The question for the day is re: passenger helmets, if you don't know for \n",
      ">certain who's gonna ride with you (like say you meet them at a .... church \n",
      ">meeting, yeah, that's the ticket)... What are some guidelines? Should I just \n",
      ">pick up another shoei in my size to have a backup helmet (XL), or should I \n",
      ">maybe get an inexpensive one of a smaller size to accomodate my likely \n",
      ">passenger? \n",
      "\n",
      "If your primary concern is protecting the passenger in the event of a\n",
      "crash, have him or her fitted for a helmet that is their size.  If your\n",
      "primary concern is complying with stupid helmet laws, carry a real big\n",
      "spare (you can put a big or small head in a big helmet, but not in a\n",
      "small one).\n",
      "\n",
      "---\n",
      "Ed Green, former Ninjaite |I was drinking last night with a biker,\n",
      "  Ed.Green@East.Sun.COM   |and I showed him a picture of you.  I said,\n",
      "DoD #0111  (919)460-8302  |\"Go on, get to know her, you'll like her!\"\n",
      " (The Grateful Dead) -->  |It seemed like the least I could do...\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(news_data.data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc982780-976d-4c32-8bad-3acb7cca2142",
   "metadata": {},
   "source": [
    ">> 텍스트 데이터 확인 결과 : 기사내용+제목+작성자+소속+이메일 등 정보 다양함\n",
    ">> 내용 빼고 제거함.(나머지 정보는 target 클래스 값과 유사한 데이터 갖고 있는 경우가 많아서)\n",
    "\n",
    "then how? remove 파라미터로 header와 footer 등 제거 가능\n",
    "also, subset 파라미터로 학습 데이터 세트와 테스트 데이터 세트 분리해서 내려받기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "021b6a94-379b-49f8-8f32-1d41ad4fb496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 데이터 크기 11314 , 테스트 데이터 크기 7532\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "# subset='train'으로 학습용 데이터만 추출, remove=('headers','footers','quotes')로 내용만 추출\n",
    "train_news=fetch_20newsgroups(subset='train',remove=('headers','footers','quotes'),random_state=156)\n",
    "X_train = train_news.data\n",
    "y_train = train_news.target\n",
    "\n",
    "# subset='test'으로 테스트 데이터만 추출, remove=('headers','footers','quotes')로 내용만 추출\n",
    "test_news=fetch_20newsgroups(subset='test',remove=('headers','footers','quotes'),random_state=156)\n",
    "X_test = test_news.data\n",
    "y_test = test_news.target\n",
    "print('학습 데이터 크기 {0} , 테스트 데이터 크기 {1}'.format(len(train_news.data) , len(test_news.data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4614df2e-1ee0-4616-a0c1-c3e6ad1caf38",
   "metadata": {},
   "source": [
    "## 2. 피처 벡터화 변환과 머신러닝 모델 학/예/평"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59dcba9b-1f03-4e25-bb76-d2a20bc7233e",
   "metadata": {},
   "source": [
    "CountVectorizer를 이용해 학습 데이터의 텍스트를 피처 벡터화하기\n",
    "- 테스트 데이터 >> 학습 데이터를 이용해 fit()이 수행된 CountVectorizer 객체로 변환해야함\n",
    "- cnt_vect.transform()해야 한다.(fit_transform() 적용 X > 테스트 데이터 기반으로 작동되기 때문에)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18f47c5f-6c04-4ae0-8ab5-f3c4f11054b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "#Count Vectorization으로 피처 벡터화 변환 수행\n",
    "cnt_vect=CountVectorizer()\n",
    "cnt_vect.fit(X_train)\n",
    "X_train_cnt_vect=cnt_vect.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21f9822c-078b-462a-9ad7-0c7719a6fa97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 데이터 Text의 CountVectorizer Shape: (11314, 101631)\n"
     ]
    }
   ],
   "source": [
    "# X_train으로 fit()된 CountVectorizer를 이용해 테스트 데이터를 피처 벡터화 변환 수행\n",
    "X_test_cnt_vect=cnt_vect.transform(X_test)\n",
    "\n",
    "print('학습 데이터 Text의 CountVectorizer Shape:',X_train_cnt_vect.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9764b071-d87d-4d84-b386-29d9a49ca225",
   "metadata": {},
   "source": [
    ">> 11314개의 문서에서 피처, 즉 단어가 101631개로 만들어짐"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b13462-7b67-47ef-9fee-746f8a1e1aa2",
   "metadata": {},
   "source": [
    "### 2-1. Count 기반으로 피처 데이터화된 데이터에 로지스틱 회귀를 적용해 분류 예측해보기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779ef8e3-90e8-424a-898f-d90ac544603a",
   "metadata": {},
   "source": [
    "#피처 데이터화된 데이터에 로지스틱 회귀를 적용해 분류 예측해보기\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# LogisticRegression을 이용해 학/예/평 수행\n",
    "lr_clf=LogisticRegression()\n",
    "lr_clf.fit(X_train_cnt_vect,y_train)\n",
    "pred=lr_clf.predict(X_test_cnt_vect)\n",
    "print('CountVectorized Logistic Regression 의 예측 정확도는 {0:.3f}'.format(accuracy_score(y_test,pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8992a55-d460-414d-b593-cae0bf48fb52",
   "metadata": {},
   "source": [
    "### 2-2. TF-IDF 기반으로 피처 데이터화된 데이터에 로지스틱 회귀를 적용해 분류 예측해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7ff05a32-0b97-420d-b83b-2204df11ada6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorized Logistic Regression 의 예측 정확도는 0.674\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# TF-IDF 벡터화를 적용해 학습 데이터 세트와 테스트 데이터 세트 변환\n",
    "tfidf_vect=TfidfVectorizer()\n",
    "tfidf_vect.fit(X_train)\n",
    "X_train_tfidf_vect=tfidf_vect.transform(X_train)\n",
    "X_test_tfidf_vect=tfidf_vect.transform(X_test)\n",
    "\n",
    "# LogisticRegression을 이용해 학/예/평 수행\n",
    "lr_clf=LogisticRegression()\n",
    "lr_clf.fit(X_train_tfidf_vect,y_train)\n",
    "pred=lr_clf.predict(X_test_tfidf_vect)\n",
    "print('CountVectorized Logistic Regression 의 예측 정확도는 {0:.3f}'.format(accuracy_score(y_test,pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aed621f-d1ad-4f3f-b0cd-5ffb7fdc091b",
   "metadata": {},
   "source": [
    "TF-IDF가 Count 기반보다 훨씬 더 높은 예측 정확도를 제공 >> 텍스트가 많고 많은 문서를 가지는 텍스트 분석에서 TF-IDF 벡터화가 좋은 예측 결과를  도출함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ad7c2d-c51e-41d0-9b56-d7f6f18e9b8f",
   "metadata": {},
   "source": [
    "### 2-3. TfidfVectorizer의 파라미터를 적용해보기(스톱워드 지정 등)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8c1db425-abd2-4ae3-ae2e-6f33b611a424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Vectorized Logistic Regression 의 예측 정확도는 0.692\n"
     ]
    }
   ],
   "source": [
    "#stop_words 필터링 추가하고 ngram을 (1,1)>(1,2)로 변경해 피처 벡터화 적용\n",
    "tfidf_vect=TfidfVectorizer(stop_words='english',ngram_range=(1,2),max_df=300)\n",
    "tfidf_vect.fit(X_train)\n",
    "X_train_tfidf_vect=tfidf_vect.transform(X_train)\n",
    "X_test_tfidf_vect=tfidf_vect.transform(X_test)\n",
    "\n",
    "lr_clf=LogisticRegression()\n",
    "lr_clf.fit(X_train_tfidf_vect,y_train)\n",
    "pred=lr_clf.predict(X_test_tfidf_vect)\n",
    "print('TF-IDF Vectorized Logistic Regression 의 예측 정확도는 {0:.3f}'.format(accuracy_score(y_test, pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2def566e-49a0-413a-8e6f-d9644f6765e1",
   "metadata": {},
   "source": [
    "### 2-4. GridSearchCV를 이용해 로지스틱 회귀 하이퍼 파라미터 최적화 수행하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c22cdfce-09cb-4837-8d51-41e43742cd9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "Logistic Regression best C parameter : {'C': 10}\n",
      "TF-IDF Vectorized Logistic Regression 의 예측 정확도는 0.701\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#최적의 C 값 도출 튜닝 수행, cv는 3폴드 세트로 설정\n",
    "params={'C':[0.01,0.1,1,5,10]}\n",
    "grid_cv_lr=GridSearchCV(lr_clf,param_grid=params,cv=3,scoring='accuracy',verbose=1)\n",
    "grid_cv_lr.fit(X_train_tfidf_vect,y_train)\n",
    "print('Logistic Regression best C parameter :',grid_cv_lr.best_params_)\n",
    "\n",
    "#최적의 C 값으로 학습된 grid_cv로 예측 및 정확도 평가\n",
    "pred=grid_cv_lr.predict(X_test_tfidf_vect)\n",
    "print('TF-IDF Vectorized Logistic Regression 의 예측 정확도는 {0:.3f}'.format(accuracy_score(y_test, pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379f3c83-0537-4540-89bc-e3de3b994a60",
   "metadata": {},
   "source": [
    ">> 로지스틱 회귀의 C가 10일때 G의 교차 검증 테스트 세트에서 가장 좋은 예측 성능을 나타냄 + 전보다 성능 수치도 향상"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f6cf4f-71eb-4bef-84b3-d9e548f79a47",
   "metadata": {},
   "source": [
    "## 3. 사이킷런 파이프라인 사용 및 GridSearchCV와의 결합"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a7400f-9930-4712-9085-9bb0de267cb5",
   "metadata": {},
   "source": [
    "- 사이킷런의 Pipeline 클래스는 데이터의 전처리와 머신러닝 학습 과정을 통일된 API 기반에서 처리할 수 있음 >> 직관적인 ML 코드 생성 가능\n",
    "  + 대용량의 데이터의 피처 벡터화 결과를 별도로 저장하지 않고 스트림 기반에서 바로 ML 데이터로 입력할 수 있음 >> 수행시간 절약\n",
    "  + 피처 벡터화랑 데이터 전처리 작업과 Estimator를 결합할 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd4eb24-b128-41be-88d0-889c729ed989",
   "metadata": {},
   "source": [
    "- TfidfVectorizer 객체를 tfidf_vect로, LogisticRegression객체를 lr_clf로 생성한 뒤 두 객체를 파이프라인으로 연결\n",
    "- TfidfVectorizer의 학습 데이터와 테스트 데이터에 대한 fit(), transform() 수행을 통한 피처 벡터화와 LogisticRegression의fit(),predict() 수행을 통한 머신러닝 모델의 학습과 예측이 Pipeline의 fit(),predict()로 통일되어 수행됨."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f3d39e2d-ceb1-4eae-a42b-73c69c5fa181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline을 통한 LogisticRegression의 예측 정확도는 0.701\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# TfidfVectorizer 객체를 tfidf_vect로, LogisticRegression객체를 lr_clf로 생성하는 Pipeline 생성\n",
    "pipeline=Pipeline([('tfidf_vect',TfidfVectorizer(stop_words='english',ngram_range=(1,2),max_df=300)),('lr_clf',LogisticRegression(C=10))])\n",
    "\n",
    "# 별도의 TfidfVectorizer 객체의 fit(), transform()과 LogisticRegression의 fit(),predict()가 필요없음\n",
    "# pipeline의 fit()과 predict()만으로 한꺼번에 피처 벡터화와 ML 학습/예측 가능\n",
    "pipeline.fit(X_train,y_train)\n",
    "pred=pipeline.predict(X_test)\n",
    "print('Pipeline을 통한 LogisticRegression의 예측 정확도는 {0:.3f}'.format(accuracy_score(y_test,pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62368729-6a9a-419d-99a4-18a3cf1f67b1",
   "metadata": {},
   "source": [
    "- GridSearchCV에 Pipeline을 입력하면서 TfidfVectorizer 파라미터와 LogisticRegression의 하이퍼 파라미터를 함께 최적화\n",
    "- GridSearchCV에 Estimator 대신 Pipeline을 입력할 경우 param_grid의 입력값 설정이 약간 다름 > Key값이 tfidf_vect_ngram_range와 같이 '하이퍼 파라미터명+객체의 변수명'으로 제공"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df51ee69-c3e0-4736-996b-fe84f28a65a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline=Pipeline([('tfidf_vect',TfidfVectorizer(stop_words='english')),('lr_clf',LogisticRegression())])\n",
    "\n",
    "# Pipeline에 기술된 각각의 객체 변수에 언더바 2개를 연달아 붙여 (하이퍼)파라미터 이름과 값을 설정\n",
    "params={'tfidf_vect__ngram_range':[(1,1),(1,2),(1,3)],'tfidf_vect__max_df':[100,300,700],'lr_clf__C':[1,5,10]}\n",
    "\n",
    "# GridSearchCV의 생성자에 Estimator가 아닌 Pipeline 객체 입력\n",
    "grid_cv_pipe=GridSearchCV(pipeline,param_grid=params,cv=3,scoring='accuracy',verbose=1)\n",
    "grid_cv_pipe.fit(X_train,y_train)\n",
    "print(grid_cv_pipe.best_params_,grid_cv_pipe.best_score_)\n",
    "\n",
    "pred=grid_cv_pipe.predict(X_test)\n",
    "print('Pipeline을 통한 LogisticRegression의 예측 정확도는 {0:.3f}'.format(accuracy_score(y_test,pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13947191-df9b-4932-a74f-cdd2fea6b7ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
